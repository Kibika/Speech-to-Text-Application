{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resize_standardize.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNRRVL0i3p546knvz7vldfr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kibika/speech-to-text/blob/speech_to_text/notebooks/resize_standardize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNZ-uW6VTDpY"
      },
      "source": [
        "import wave\n",
        "import os\n",
        "import librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AvTP8ecTFFP"
      },
      "source": [
        "Path_to_train = \"train\\wav\"\n",
        "subfolders = os.listdir(Path_to_train)\n",
        "data = []\n",
        "for s in subfolders:\n",
        "    files = os.listdir(Path_to_train + \"/\" +s)\n",
        "    data.extend([Path_to_train + \"/\" + s+ \"/\" + f for f in files])\n",
        "data[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeZyvnnJTFHf"
      },
      "source": [
        "#read text from every transcription audio\n",
        "def read_text( text_path):\n",
        "    text = []\n",
        "    with open(text_path) as fp:\n",
        "        line = fp.readline()\n",
        "        while line:\n",
        "        # TODO: fix spaces in in amharic text\n",
        "            text.append(line)\n",
        "            line = fp.readline()\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykuyj212TFK-"
      },
      "source": [
        "#extract the transcription and the label \n",
        "label=[]\n",
        "transcriptions = []\n",
        "for t in text:\n",
        "    sp = t.split(\"\\t\")\n",
        "    sp = sp.strip(\"\\n\")\n",
        "    if len(sp) > 1:\n",
        "        label.append(sp[0])\n",
        "        transcriptions.append(sp[1])\n",
        "transcriptions[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8mqLRCHTY8L"
      },
      "source": [
        "#get audio path , every path must corespond to transcription , get the transprion in the doc and append to audio path \n",
        "audio_path=[0]*len(transcriptions)\n",
        "for d in data:\n",
        "    _d = d.strip(\".wav\")\n",
        "    sp = _d.split(\"/\")[2]\n",
        "    index = label.index(sp)\n",
        "    audio_path[index] = d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atBdLgb2TY_i"
      },
      "source": [
        "#calculate duration \n",
        "duration_of_recordings=[]\n",
        "for d in audio_path:\n",
        "    audio, fs = librosa.load(d, sr=None)\n",
        "    duration_of_recordings.append(float(len(audio)/fs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuUupPpyTZCP"
      },
      "source": [
        "import pandas as pd \n",
        "data=pd.DataFrame({'key': audio_path,'text': transcriptions, 'duration':duration_of_recordings})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfqPBqisTsd0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mNnSAu0rvhl"
      },
      "source": [
        "# Resize and standardize\n",
        "We resize all the audio samples to have the same length by either extending its duration by padding it with silence, or by truncating it.\n",
        "We use the right padding method\n",
        "\n",
        "Standardize the sample rate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNbZwxa3TFOX"
      },
      "source": [
        "# used to load audio file\n",
        "#specifying sample rate will resize all the files i.e Audio will be automatically resampled to the given rate\n",
        "class Loader:\n",
        "  def __init__(self, sample_rate,duration,mono):\n",
        "    self.sample_rate=sample_rate\n",
        "    self.duration=duration\n",
        "    self.mono=mono\n",
        "\n",
        "  def load_signal(self, filepath):\n",
        "    signal=librosa.load(filepath,\n",
        "                        sr=self.sample_rate,\n",
        "                        duration=self.duration,\n",
        "                        mono=self.mono)[0]    #librosa returns 2D array (signal,sample_rate) pick the signal here\n",
        "    return signal\n",
        "\n",
        "  def load_sample_rate(self,filepath):\n",
        "    sample_rate=librosa.load(filepath,\n",
        "                        sr=self.sample_rate,\n",
        "                        duration=self.duration,\n",
        "                        mono=self.mono)[1]    #librosa returns 2D array (signal,sample_rate) pick the sample rate here\n",
        "    return sample_rate\n",
        "\n",
        "  def load(self,filepath):     #get both signal and sample rate in one\n",
        "    aud=librosa.load(filepath,\n",
        "                        sr=self.sample_rate,\n",
        "                        duration=self.duration,\n",
        "                        mono=self.mono)\n",
        "    return aud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikidMk81TFQt"
      },
      "source": [
        "#resizes audios to have same length\n",
        "class Padder:\n",
        "  def __init__(self,mode=\"constant\"):\n",
        "    self.mode=mode\n",
        "  def left_pad(self,array,num_missing_items):\n",
        "    padded_array=np.pad(array,\n",
        "                        (num_missing_items, 0),\n",
        "                        mode=self.mode)\n",
        "    return padded_array\n",
        "  def right_pad(self,array,num_missing_items):\n",
        "    padded_array=np.pad(array,\n",
        "                        (0,num_missing_items),\n",
        "                        mode=self.mode)\n",
        "    return padded_array\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkLUE2j5TFS0"
      },
      "source": [
        "class PreprocessingPipeline:\n",
        "  '''Processes audio files in a directory by applying the following steps\n",
        "    1. Load the data, convert to mono and resample sampling rate\n",
        "    2. Pad the audio\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    self.padder=None\n",
        "    # self.saver=None\n",
        "    self._loader=None\n",
        "    # self._num_expected_samples=None\n",
        "\n",
        "\n",
        " \n",
        "  # def loader(self):\n",
        "  #   return self._loader\n",
        "\n",
        "\n",
        " \n",
        "  # def loader(self,loader):\n",
        "  #   self.loader=loader\n",
        "  #   self._num_expected_samples=int(loader.sample_rate*loader.duration)\n",
        "\n",
        "\n",
        "\n",
        "  def process(self,audio_files_directory):\n",
        "    for root, directories, files in os.walk(audio_files_directory):\n",
        "        for filename in files:\n",
        "            filepath = os.path.join(root, filename)\n",
        "            self._process_file(filepath)\n",
        "            print(f\"Processed file {filepath}\")\n",
        "    \n",
        "  def _process_file(self,filepath):\n",
        "    signal=self.loader.load_signal(filepath)\n",
        "    if self._is_padding_necessary(signal):\n",
        "      signal=self._apply_padding(signal)\n",
        "\n",
        "  def _is_padding_necessary(self,signal):\n",
        "    num_expected_samples=int(loader.sample_rate*loader.duration)\n",
        "    if len(signal) < num_expected_samples:\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  def apply_padding(self,signal):\n",
        "    num_missing_samples=self._num_expected_samples - len(signal)\n",
        "    padded_signal = self.padder.right_pad(signal, num_missing_samples)\n",
        "    return padded_signal\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeWtzfg9TFVS"
      },
      "source": [
        "DURATION=0.74\n",
        "SAMPLE_RATE=22050\n",
        "MONO=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObprKDYvUPOb"
      },
      "source": [
        "loader=Loader(SAMPLE_RATE, DURATION, MONO)\n",
        "padder=Padder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBtGze_5UPRG"
      },
      "source": [
        "preprocessing_pipeline=PreprocessingPipeline()\n",
        "preprocessing_pipeline.loader=loader\n",
        "preprocessing_pipeline.padder=padder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf0oX_sfUPT-"
      },
      "source": [
        "preprocessing_pipeline.process(Path_to_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef5TTLS0UPm7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}