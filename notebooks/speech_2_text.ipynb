{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech_2_text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kibika/speech-to-text/blob/speech_to_text/notebooks/speech_2_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Biz2VmyTI6RG"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8n3ch_5RI8H8",
        "outputId": "204c90db-6819-4efd-bcac-cb182141e4de"
      },
      "source": [
        "!pip install dvc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dvc\n",
            "  Downloading dvc-2.5.4-py3-none-any.whl (638 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 81 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 194 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 225 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 245 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 256 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 276 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 286 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 296 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 307 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 327 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 368 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 389 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 409 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 419 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 430 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 440 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 450 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 460 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 471 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 481 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 491 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 501 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 512 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 522 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 532 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 542 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 552 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 563 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 573 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 583 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 593 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 604 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 614 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 624 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 634 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 638 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting voluptuous>=0.11.7\n",
            "  Downloading voluptuous-0.12.1-py3-none-any.whl (29 kB)\n",
            "Collecting zc.lockfile>=1.2.1\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting rich>=10.0.0\n",
            "  Downloading rich-10.6.0-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 73.3 MB/s \n",
            "\u001b[?25hCollecting dulwich>=0.20.23\n",
            "  Downloading dulwich-0.20.24-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 52.6 MB/s \n",
            "\u001b[?25hCollecting ply>=3.9\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.7/dist-packages (from dvc) (57.2.0)\n",
            "Collecting pathspec>=0.6.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting funcy>=1.14\n",
            "  Downloading funcy-1.16-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.7/dist-packages (from dvc) (21.0)\n",
            "Requirement already satisfied: pydot>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from dvc) (1.3.0)\n",
            "Collecting tqdm<5,>=4.45.0\n",
            "  Downloading tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from dvc) (3.7.4.3)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting grandalf==0.6\n",
            "  Downloading grandalf-0.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.7/dist-packages (from dvc) (0.8.9)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from dvc) (2.4.7)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from dvc) (2.23.0)\n",
            "Collecting jsonpath-ng>=1.5.1\n",
            "  Downloading jsonpath_ng-1.5.3-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: networkx~=2.5 in /usr/local/lib/python3.7/dist-packages (from dvc) (2.5.1)\n",
            "Collecting dpath<3,>=2.0.1\n",
            "  Downloading dpath-2.0.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from dvc) (4.6.1)\n",
            "Collecting flatten-dict<1,>=0.3.0\n",
            "  Downloading flatten_dict-0.4.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: pyasn1>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from dvc) (0.4.8)\n",
            "Collecting distro>=1.3.0\n",
            "  Downloading distro-1.6.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from dvc) (1.4.4)\n",
            "Collecting gitpython>3\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 65.9 MB/s \n",
            "\u001b[?25hCollecting flufl.lock<4,>=3.2\n",
            "  Downloading flufl.lock-3.2.tar.gz (19 kB)\n",
            "Collecting fsspec>=2021.6.1\n",
            "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 69.3 MB/s \n",
            "\u001b[?25hCollecting nanotime>=0.5.2\n",
            "  Downloading nanotime-0.5.2.tar.gz (3.2 kB)\n",
            "Collecting pygtrie>=2.3.2\n",
            "  Downloading pygtrie-2.4.2.tar.gz (35 kB)\n",
            "Collecting python-benedict>=0.21.1\n",
            "  Downloading python_benedict-0.24.1-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting pygit2>=1.5.0\n",
            "  Downloading pygit2-1.6.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 44.2 MB/s \n",
            "\u001b[?25hCollecting psutil>=5.8.0\n",
            "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n",
            "\u001b[K     |████████████████████████████████| 296 kB 70.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from dvc) (0.10.2)\n",
            "Collecting dictdiffer>=0.8.1\n",
            "  Downloading dictdiffer-0.9.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting ruamel.yaml>=0.16.1\n",
            "  Downloading ruamel.yaml-0.17.10-py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 70.8 MB/s \n",
            "\u001b[?25hCollecting diskcache>=5.2.1\n",
            "  Downloading diskcache-5.2.1-py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting shtab<2,>=1.3.4\n",
            "  Downloading shtab-1.3.9-py2.py3-none-any.whl (12 kB)\n",
            "Collecting configobj>=5.0.6\n",
            "  Downloading configobj-5.0.6.tar.gz (33 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from grandalf==0.6->dvc) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from configobj>=5.0.6->dvc) (1.15.0)\n",
            "Requirement already satisfied: urllib3>=1.24.1 in /usr/local/lib/python3.7/dist-packages (from dulwich>=0.20.23->dvc) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from dulwich>=0.20.23->dvc) (2021.5.30)\n",
            "Collecting atpublic\n",
            "  Downloading atpublic-2.3.tar.gz (16 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->dvc) (3.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from jsonpath-ng>=1.5.1->dvc) (4.4.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from pygit2>=1.5.0->dvc) (1.5.2)\n",
            "Requirement already satisfied: cffi>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pygit2>=1.5.0->dvc) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.4.0->pygit2>=1.5.0->dvc) (2.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from python-benedict>=0.21.1->dvc) (2.8.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from python-benedict>=0.21.1->dvc) (3.13)\n",
            "Collecting mailchecker\n",
            "  Downloading mailchecker-4.0.11.tar.gz (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 68.0 MB/s \n",
            "\u001b[?25hCollecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting phonenumbers\n",
            "  Downloading phonenumbers-8.12.28-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 51.6 MB/s \n",
            "\u001b[?25hCollecting python-fsutil\n",
            "  Downloading python_fsutil-0.5.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from python-benedict>=0.21.1->dvc) (5.0.2)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->dvc) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->dvc) (2.10)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.0.0->dvc) (2.6.1)\n",
            "Collecting ruamel.yaml.clib>=0.1.2\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 66.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->python-benedict>=0.21.1->dvc) (0.2.5)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->python-benedict>=0.21.1->dvc) (1.3)\n",
            "Building wheels for collected packages: configobj, dpath, flufl.lock, nanotime, pygtrie, atpublic, ftfy, mailchecker\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-py3-none-any.whl size=34547 sha256=bfda1dd940e3fb0c5f8b39fa7f454a13f78f022ceb0aca62a1f5b52a868294a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/c4/19/13d74440f2a571841db6b6e0a273694327498884dafb9cf978\n",
            "  Building wheel for dpath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dpath: filename=dpath-2.0.1-py3-none-any.whl size=15153 sha256=fa90a3a969bc5889b5b2aee83edc9e7f918d20b17635499e546c3c7f3fdf0805\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/f8/ae/bc69cb5f61393ebf9ade4cde41d1a813d35bfe78263a26f99e\n",
            "  Building wheel for flufl.lock (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flufl.lock: filename=flufl.lock-3.2-py3-none-any.whl size=19927 sha256=d4e28383bd627dac26e1fb675f28f471d80acecbe10636538b695fcb05559e59\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/68/a0/8e7cb7bbf4990fc10b5a082aa0eb3ac66787ca11e8eca445b2\n",
            "  Building wheel for nanotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nanotime: filename=nanotime-0.5.2-py3-none-any.whl size=2440 sha256=0134a96e29f6638c8925350a9a6a214353c972faf6fa24757e2ba747be25499d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/92/aa/456d462c908b4e210c3928f778d28f94049fc9e47af8b191c9\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygtrie: filename=pygtrie-2.4.2-py3-none-any.whl size=19061 sha256=8f1c093305b8c66bed1ea896322f2e60ea94d96b22cd99a65280a67e462afbd6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/f8/ba/1d828b1603ea422686eb694253a43cb3a5901ea4696c1e0603\n",
            "  Building wheel for atpublic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for atpublic: filename=atpublic-2.3-py3-none-any.whl size=5032 sha256=ebcaa7dfd0daa078a39c75d60c4355e139ad40ac4c03537aedd4641f37056015\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/d9/0f/54be2ecb4bcb1612f987f0b6482d88fa7f3e43d3946f36a32a\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41934 sha256=87864792edaf4042c87b2cc5f714934946f884b28c0e79516656c2f44dda1128\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for mailchecker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mailchecker: filename=mailchecker-4.0.11-py3-none-any.whl size=201671 sha256=10c272c91c44f0f740d745aa7fe208cc2918b79a03000aff904b5a3777742096\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/cd/39/230bf7caff55afc08eb4a1d433731706d76fde0b95d70df3ca\n",
            "Successfully built configobj dpath flufl.lock nanotime pygtrie atpublic ftfy mailchecker\n",
            "Installing collected packages: smmap, xmltodict, ruamel.yaml.clib, python-fsutil, ply, phonenumbers, mailchecker, gitdb, ftfy, commonmark, colorama, atpublic, zc.lockfile, voluptuous, tqdm, shtab, shortuuid, ruamel.yaml, rich, python-benedict, pygtrie, pygit2, psutil, pathspec, nanotime, jsonpath-ng, grandalf, gitpython, funcy, fsspec, flufl.lock, flatten-dict, dulwich, dpath, distro, diskcache, dictdiffer, configobj, dvc\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed atpublic-2.3 colorama-0.4.4 commonmark-0.9.1 configobj-5.0.6 dictdiffer-0.9.0 diskcache-5.2.1 distro-1.6.0 dpath-2.0.1 dulwich-0.20.24 dvc-2.5.4 flatten-dict-0.4.1 flufl.lock-3.2 fsspec-2021.7.0 ftfy-6.0.3 funcy-1.16 gitdb-4.0.7 gitpython-3.1.18 grandalf-0.6 jsonpath-ng-1.5.3 mailchecker-4.0.11 nanotime-0.5.2 pathspec-0.9.0 phonenumbers-8.12.28 ply-3.11 psutil-5.8.0 pygit2-1.6.1 pygtrie-2.4.2 python-benedict-0.24.1 python-fsutil-0.5.0 rich-10.6.0 ruamel.yaml-0.17.10 ruamel.yaml.clib-0.2.6 shortuuid-1.0.1 shtab-1.3.9 smmap-4.0.0 tqdm-4.62.0 voluptuous-0.12.1 xmltodict-0.12.0 zc.lockfile-2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5o9vNjRIxZs",
        "outputId": "fd48802a-8f9b-4b22-c24c-98eaa296e24f"
      },
      "source": [
        "pip install torchaudio"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvGGQqBYucEE",
        "outputId": "f2d0bcef-03d3-4ab3-a837-567e22375c0e"
      },
      "source": [
        "! pip install SpeechRecognition"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 31 kB/s \n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28zEvN66I8Ji",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "1828df52-a8d2-4fcc-88bb-66124d259dfe"
      },
      "source": [
        "!pip install mlflow --quiet\n",
        "import mlflow\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ['MLFLOW_TRACKING_USERNAME'] = input('Enter your DAGsHub username: ')\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = getpass('Enter your DAGsHub access token: ')\n",
        "os.environ['MLFLOW_TRACKING_PROJECTNAME'] = input('Enter your DAGsHub project name: ')\n",
        "\n",
        "mlflow.set_tracking_uri(f'https://dagshub.com/' + os.environ['MLFLOW_TRACKING_USERNAME'] \n",
        "                        + '/' + os.environ['MLFLOW_TRACKING_PROJECTNAME'] + '.mlflow')\n",
        "\n",
        "with mlflow.start_run(run_name=\"MLflow on Colab\"):\n",
        "  mlflow.log_metric(\"m1\", 2.0)\n",
        "  mlflow.log_param(\"p1\", \"mlflow-colab\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 14.4 MB 64 kB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 54.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 45.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 146 kB 68.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 75 kB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 9.0 MB/s \n",
            "\u001b[?25h  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-98b6ee70388f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgetpass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MLFLOW_TRACKING_USERNAME'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter your DAGsHub username: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MLFLOW_TRACKING_PASSWORD'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter your DAGsHub access token: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MLFLOW_TRACKING_PROJECTNAME'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter your DAGsHub project name: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuqGfRIaI8Mm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "6d13f24e-986c-45a7-f020-95d27acdb942"
      },
      "source": [
        "# See your experiments table inside Colab!\n",
        "import IPython\n",
        "display(IPython.display.IFrame(\"https://dagshub.com/\"+ os.environ['MLFLOW_TRACKING_USERNAME'] \n",
        "                        + '/' + os.environ['MLFLOW_TRACKING_PROJECTNAME'] + \"/experiments/#/\",'100%',600))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6f6369700a93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m display(IPython.display.IFrame(\"https://dagshub.com/\"+ os.environ['MLFLOW_TRACKING_USERNAME'] \n\u001b[0;32m----> 4\u001b[0;31m                         + '/' + os.environ['MLFLOW_TRACKING_PROJECTNAME'] + \"/experiments/#/\",'100%',600))\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'MLFLOW_TRACKING_USERNAME'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WprqRQcYGQk8"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ureWLb7MQ3M"
      },
      "source": [
        "# cd drive/MyDrive/speech"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epO8_pIbkj0g",
        "outputId": "254e8b49-b351-4a96-a6e2-fa7054a663eb"
      },
      "source": [
        "! git clone https://github.com/getalp/ALFFA_PUBLIC.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ALFFA_PUBLIC'...\n",
            "remote: Enumerating objects: 66024, done.\u001b[K\n",
            "remote: Total 66024 (delta 0), reused 0 (delta 0), pack-reused 66024\u001b[K\n",
            "Receiving objects: 100% (66024/66024), 6.54 GiB | 24.88 MiB/s, done.\n",
            "Resolving deltas: 100% (12337/12337), done.\n",
            "Checking out files: 100% (56925/56925), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqbfMfu6rQVr"
      },
      "source": [
        "# ! git clone https://github.com/Kibika/speech-to-text.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcTr-9heiL0M"
      },
      "source": [
        "# ! git init "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCB_2C56hfuM"
      },
      "source": [
        "# #connect to github\n",
        "# # configuring git for user account\n",
        "# ! git config --global user.name \"Kibika\" #<github user id>\n",
        "# ! git config --global user.email \"steshykibika@gmail.com\" #<github email id>\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ow-APJYbgfa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjYIebttGn8R"
      },
      "source": [
        "# Read the dataset from github\n",
        "Thhe dataset is contained in several folders in a git repo. The repo containing the data is cloned and os.walk is used to extract the .wav files from the subdirectories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rkn2kATKbD0"
      },
      "source": [
        "import wave\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "import librosa\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Mi3CMKsVUZ"
      },
      "source": [
        "# dataset = pd.read_csv(\"/content/drive/My Drive/Bank Statements/newcustomerdata.csv\")\n",
        "Path_to_train = \"/content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav\"\n",
        "Path_to_test = \"/content/ALFFA_PUBLIC/ASR/SWAHILI/data/test/wav5\"\n",
        "Path_to_train_labels = \"/content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/text\"\n",
        "Path_to_test_labels=\"/content/ALFFA_PUBLIC/ASR/SWAHILI/data/test/text\"\n",
        "OUTPUTFILE = '/content/speech-to-text/data/speech_features.csv'\n",
        "# speech_data_nofeatures=[]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL2uvp-utumZ"
      },
      "source": [
        "#extract all .wav from subdirectories\n",
        "def get_file_paths(dirname):\n",
        "    file_paths = []  \n",
        "    for root, directories, files in os.walk(dirname):\n",
        "        for filename in files:\n",
        "            filepath = os.path.join(root, filename)\n",
        "            file_paths.append(filepath)  \n",
        "    return file_paths  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W9uufSqhl0x"
      },
      "source": [
        "#create a folder with all the train files\n",
        "import shutil\n",
        "in_path = Path_to_train\n",
        "out_path = \"/content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/all_files\"\n",
        " \n",
        "for dirpath, dirnames, filenames in os.walk(in_path):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith(\".wav\"):\n",
        "             src = os.path.join(dirpath, filename)\n",
        "             dest = os.path.join(out_path, filename)\n",
        "             shutil.copy2(src, dest)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnfRSHwvu7GG"
      },
      "source": [
        "#Process the data\n",
        "# def process_file(file):\n",
        "#     r = sr.Recognizer()\n",
        "#     a = ''\n",
        "#     with sr.AudioFile(file) as source:\n",
        "#         audio = r.record(source)    \n",
        "#         try:\n",
        "#             a =  r.recognize_google(audio)        \n",
        "#         except sr.UnknownValueError:\n",
        "#             a = \"Google Speech Recognition could not understand audio\"\n",
        "#         except sr.RequestError as e:\n",
        "#             a = \"Could not request results from Google Speech Recognition service; {0}\".format(e)  \n",
        "#     return a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVIw_g9rvsDf"
      },
      "source": [
        "# def main():\n",
        "#     files = get_file_paths(Path_to_train)                 # get all file-paths of all files in dirname and subdirectories\n",
        "#     for file in files:                              # execute for each file\n",
        "#         (filepath, ext) = os.path.splitext(file)    # get the file extension\n",
        "#         file_name = os.path.basename(file)          # get the basename for writing to output file\n",
        "#         if ext == '.wav':                           # only interested if extension is '.wav'\n",
        "#             a = process_file(file)                  # result is returned to a\n",
        "#             with open(OUTPUTFILE, 'a') as f:        # write results to file\n",
        "#                 writer = csv.writer(f)\n",
        "#                 writer.writerow(['file_name','google'])\n",
        "#                 writer.writerow([file_name, a])        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bdqDaYOI8xA"
      },
      "source": [
        "# #put extracted .wav files into a dataframe\n",
        "# speech_df = pd.DataFrame (get_file_paths(Path_to_train),columns=['recording'])\n",
        "# speech_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-N9Di52Q4bB"
      },
      "source": [
        "# #extract content of text file(labels)\n",
        "# text_labels=pd.DataFrame(pd.read_csv(Path_to_train_labels, sep=',',header=None, names=['file_path'])['file_path'].str.split('\\t',1).tolist(),\n",
        "#                                  columns = ['file_path','text'])\n",
        "# text_labels.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06Kauu5eLEt1"
      },
      "source": [
        "pd.set_option('display.max_colwidth',None)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwO_pOvDG-85"
      },
      "source": [
        "Read in the labels data from .txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLO_R3NcRgMD"
      },
      "source": [
        "#merge dataframes based on the name of the file path use metadata\n",
        "\n",
        "#read text from every transcription audio\n",
        "def read_text( text_path):\n",
        "    text = []\n",
        "    with open(text_path) as fp:\n",
        "        line = fp.readline()\n",
        "        while line:\n",
        "            text.append(line)\n",
        "            line = fp.readline()\n",
        "    return text\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvQpi6QJHPWX"
      },
      "source": [
        "obtain the data folder name and texts from the .txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpcfW7iO_Lq4"
      },
      "source": [
        "label=[]\n",
        "transcriptions = []\n",
        "for t in read_text(Path_to_train_labels):\n",
        "    name=t.split(\"\\t\")[1]\n",
        "    # name=name.replace('(', '')\n",
        "    # name=name.replace(')', '')\n",
        "    name=name.replace('\\n','')\n",
        "    # name=name.replace(' ','')\n",
        "    text=t.split(\"\\t\")[0]\n",
        "    # text=text.replace(\"\\t\",\"\")\n",
        "    # name_to_text[name]=text\n",
        "    label.append(text)\n",
        "    transcriptions.append(name)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-OryygpU-wN"
      },
      "source": [
        "#get audio path , every path must corespond to transcription , get the transprion in the doc and append to audio path \n",
        "audio_path=[0]*len(transcriptions)\n",
        "for d in get_file_paths(Path_to_train):\n",
        "    _d = d.strip(\".wav\")\n",
        "    sp = _d.split(\"/\")[9]\n",
        "    index = label.index(sp)\n",
        "    audio_path[index] = d"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3czSMhYU-y7"
      },
      "source": [
        "#calculate duration \n",
        "duration_of_recordings=[]\n",
        "for d in audio_path:\n",
        "    audio, fs = librosa.load(d, sr=None)\n",
        "    duration_of_recordings.append(float(len(audio)/fs))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ7OjF1CU-4s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "62c45137-3b6c-4104-e5ec-6b43df449c46"
      },
      "source": [
        "speech_data=pd.DataFrame({'key': audio_path,'text': transcriptions, 'duration':duration_of_recordings})\n",
        "speech_data.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>text</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part10.wav</td>\n",
              "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
              "      <td>3.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part100.wav</td>\n",
              "      <td>yanayo andaliwa nami pendo pondo idhaa ya kiswahili</td>\n",
              "      <td>3.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part101.wav</td>\n",
              "      <td>inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania</td>\n",
              "      <td>3.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part102.wav</td>\n",
              "      <td>juma hili bara la afrika limeshuhudia raia wa nchi za niger</td>\n",
              "      <td>3.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part103.wav</td>\n",
              "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
              "      <td>2.94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                           key  ... duration\n",
              "0   /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part10.wav  ...     3.14\n",
              "1  /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part100.wav  ...     3.10\n",
              "2  /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part101.wav  ...     3.65\n",
              "3  /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part102.wav  ...     3.90\n",
              "4  /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part103.wav  ...     2.94\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVUo85-bN7vB"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laXWIEqMlGan"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSHG0miCj-FP"
      },
      "source": [
        "recognizer = sr.Recognizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8-i8dq2j-IF"
      },
      "source": [
        "# set energy threshold\n",
        "# audios that are below this threshold will be considered silent\n",
        "recognizer.energy_threshold = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mNnSAu0rvhl"
      },
      "source": [
        "# Resize and standardize\n",
        "We resize all the audio samples to have the same length by either extending its duration by padding it with silence, or by truncating it.\n",
        "\n",
        "Standardize the sample rate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rozjR4IxrpO_"
      },
      "source": [
        "# used to load audio file\n",
        "#specifying sample rate will resize all the files i.e Audio will be automatically resampled to the given rate\n",
        "class Loader:\n",
        "  def __init__(self, sample_rate,duration,mono):\n",
        "    self.sample_rate=sample_rate\n",
        "    self.duration=duration\n",
        "    self.mono=mono\n",
        "    self.channel = 2\n",
        "\n",
        "  def load_signal(self, filepath):\n",
        "    signal=librosa.load(filepath,\n",
        "                        sr=None,\n",
        "                        duration=self.duration,\n",
        "                        mono=self.mono)[0]    #librosa returns 2D array (signal,sample_rate) pick the signal here\n",
        "    return signal\n",
        "\n",
        "  def load_sample_rate(self,filepath):\n",
        "    self.sample_rate=librosa.load(filepath,\n",
        "                        sr =None,\n",
        "                        duration=self.duration,\n",
        "                        mono=self.mono)[1]    #librosa returns 2D array (signal,sample_rate) pick the sample rate here\n",
        "    return self.sample_rate\n",
        "\n",
        "  # def load(self,filepath):     #get both signal and sample rate in one\n",
        "  #   aud=librosa.load(filepath,\n",
        "  #                       sr=None,\n",
        "  #                       duration=self.duration,\n",
        "  #                       mono=self.mono)\n",
        "  #   return aud\n",
        "\n",
        "  def load(self,filepath):\n",
        "    sig, sr = torchaudio.load(filepath)\n",
        "    aud = sig, sr\n",
        "    return aud\n",
        "\n",
        "  def rechannel(self, aud):    #convert mono to stereo\n",
        "    # aud=self.aud\n",
        "    sig, sr = aud\n",
        "  \n",
        "\n",
        "    if (sig.shape[0] == self.channel):\n",
        "      # Nothing to do\n",
        "      return self.aud\n",
        "\n",
        "    if (self.channel == 1):\n",
        "      # Convert from stereo to mono by selecting only the first channel\n",
        "      resig = sig[:1, :]\n",
        "    else:\n",
        "      # Convert from mono to stereo by duplicating the first channel\n",
        "      resig = torch.cat([sig, sig])\n",
        "\n",
        "    aud = resig, sr\n",
        "\n",
        "    return aud\n",
        "\n",
        "  def resample(self,aud):                    #standardize sample rate\n",
        "    sig, sr = aud\n",
        "    \n",
        "    if (sr == self.sample_rate):\n",
        "      # Nothing to do\n",
        "      return aud[0]\n",
        "\n",
        "    num_channels = sig.shape[0]\n",
        "    # Resample first channel\n",
        "    resig = torchaudio.transforms.Resample(sr, self.sample_rate)(sig[:1,:])\n",
        "    if (num_channels > 1):\n",
        "      # Resample the second channel and merge both channels\n",
        "      retwo = torchaudio.transforms.Resample(sr, self.sample_rate)(sig[1:,:])\n",
        "      resig = torch.cat([resig, retwo])\n",
        "      aud = resig, self.sample_rate\n",
        "    return aud\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jgn7qGOj-Nr"
      },
      "source": [
        "#resizes audios to have same length\n",
        "class Padder:\n",
        "  def __init__(self,mode=\"constant\"):\n",
        "    self.mode=mode\n",
        "  def left_pad(self,array,num_missing_items):\n",
        "    padded_array=np.pad(array,\n",
        "                        (num_missing_items, 0),\n",
        "                        mode=self.mode)\n",
        "    return padded_array\n",
        "  def right_pad(self,array,num_missing_items):\n",
        "    padded_array=np.pad(array,\n",
        "                        (0,num_missing_items),\n",
        "                        mode=self.mode)\n",
        "    return padded_array\n",
        "  \n",
        "\n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY2jY4u45JDT"
      },
      "source": [
        "class Saver():\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abm3oe9mj-VZ"
      },
      "source": [
        "class PreprocessingPipeline:\n",
        "  '''Processes audio files in a directory by applying the following steps\n",
        "    1. Load the data, convert to mono and resample sampling rate\n",
        "    2. Pad the audio\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    self.padder=None\n",
        "    # self.saver=None\n",
        "    self._loader=None\n",
        "    # self._num_expected_samples=None\n",
        "   \n",
        "\n",
        " \n",
        "  # def loader(self):\n",
        "  #   return self._loader\n",
        "\n",
        "\n",
        " \n",
        "  # def loader(self,loader):\n",
        "  #   self.loader=loader\n",
        "  #   self._num_expected_samples=int(loader.sample_rate*loader.duration)\n",
        "\n",
        "\n",
        "\n",
        "  def process(self,audio_files_directory):\n",
        "    for root, directories, files in os.walk(audio_files_directory):\n",
        "        for filename in files:\n",
        "            filepath = os.path.join(root, filename)\n",
        "            self._process_file(filepath)\n",
        "            print(f\"Processed file {filepath}\")\n",
        "    \n",
        "  def _process_file(self,filepath):\n",
        "    signal=self.loader.load(filepath)\n",
        "    signal = self.loader.rechannel(signal)\n",
        "    signal = self.loader.resample(signal)[0]\n",
        "    if self._is_padding_necessary(signal):\n",
        "      signal=self._apply_padding(signal)\n",
        "    \n",
        "\n",
        "  def _is_padding_necessary(self,signal):\n",
        "    self.num_expected_samples=int(loader.sample_rate*loader.duration)\n",
        "    if len(signal) < self.num_expected_samples:\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  def _apply_padding(self,signal):\n",
        "    num_missing_samples=self.num_expected_samples - len(signal)\n",
        "    padded_signal = self.padder.right_pad(signal, num_missing_samples)\n",
        "    return padded_signal\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMYB34TAj-Ys"
      },
      "source": [
        "DURATION=0.74\n",
        "SAMPLE_RATE=22050\n",
        "MONO=False"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNfOS0DJEIoB"
      },
      "source": [
        "loader=Loader(SAMPLE_RATE, DURATION, MONO)\n",
        "padder=Padder()"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F8xK9FiEkRT"
      },
      "source": [
        "# import sys\n",
        "# sys.setrecursionlimit(5000)\n",
        "preprocessing_pipeline=PreprocessingPipeline()\n",
        "preprocessing_pipeline.loader=loader\n",
        "preprocessing_pipeline.padder=padder"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvSQRb_NFSjf",
        "outputId": "791eb084-0125-44b6-a8c8-7c9015c6dd1c"
      },
      "source": [
        "preprocessing_pipeline.process(Path_to_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part108.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part66.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part203.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part206.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part87.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part188.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part182.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part131.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part94.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part190.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part179.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part22.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part202.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part138.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part34.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part149.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part137.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part91.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part70.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part199.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part127.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part129.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part80.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part147.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part178.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part3.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part187.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part181.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part13.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part44.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part102.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part31.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part14.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part82.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part83.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part132.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part153.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part10.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part130.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part16.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part184.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part55.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part144.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part164.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part200.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part23.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part37.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part186.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part74.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part90.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part78.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part157.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part30.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part145.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part58.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part177.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part68.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part64.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part85.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part36.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part67.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part2.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part39.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part99.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part154.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part49.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part192.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part167.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part50.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part47.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part142.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part5.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part88.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part126.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part115.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part18.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part26.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part107.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part104.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part46.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part29.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part84.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part81.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part15.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part170.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part125.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part136.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part135.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part173.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part6.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part71.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part117.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part42.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part57.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part112.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part110.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part32.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part150.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part48.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part113.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part133.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part35.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part7.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part146.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part162.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part103.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part11.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part156.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part4.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part119.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part196.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part168.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part24.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part51.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part61.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part21.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part180.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part198.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part122.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part152.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part45.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part76.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part128.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part54.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part95.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part160.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part86.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part161.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part195.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part116.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part97.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part120.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part53.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part41.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part72.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part114.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part40.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part189.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part59.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part191.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part100.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part111.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part139.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part8.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part148.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part141.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part172.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part151.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part205.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part20.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part204.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part193.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part62.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part121.wav\n",
            "Processed file /content/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part69.wav\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}